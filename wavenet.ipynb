{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replication of Wavenet in Pytorch for Character-Level Prediction Model\n",
    "\n",
    "paper: https://arxiv.org/abs/1609.03499"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%reset -f\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import seaborn as sns\n",
    "import random\n",
    "from methods import Linear, Tanh, BatchNorm1D, Embedding, Flatten, Sequential"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data and Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list, 32033, ['emma', 'olivia', 'ava'])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading names from input file\n",
    "\n",
    "names = open('names.txt', mode='r').read().splitlines()\n",
    "\n",
    "type(names), len(names), names[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fc619543690>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# defining constants and hyper-parameters\n",
    "\n",
    "START_END_CH = '.'\n",
    "NUM_OF_PREV_CHAR_TO_USE = 8\n",
    "EMBEDDING_DIM = 10\n",
    "TRAIN_VALIDATION_TEST_SPLIT = (0.8, 0.1, 0.1)\n",
    "NUMBER_OF_NEURONS = 68 # how many nodes in the hidden layer?\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8, 'i': 9, 'j': 10, 'k': 11, 'l': 12, 'm': 13, 'n': 14, 'o': 15, 'p': 16, 'q': 17, 'r': 18, 's': 19, 't': 20, 'u': 21, 'v': 22, 'w': 23, 'x': 24, 'y': 25, 'z': 26, '.': 0}\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "# creating a lookup between characters to alphabet index, and vice versa\n",
    "\n",
    "stoi = {ch: (i+1) for i, ch in enumerate(sorted(set(''.join(names))))}\n",
    "stoi[START_END_CH] = 0\n",
    "itos = {i: ch for ch, i in stoi.items()}\n",
    "\n",
    "# useful additional constant\n",
    "VOCAB_SIZE = len(stoi.items())\n",
    "\n",
    "print(stoi)\n",
    "print(VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([182625, 8]),\n",
       " torch.Size([182625]),\n",
       " torch.Size([22655, 8]),\n",
       " torch.Size([22655, 8]),\n",
       " torch.Size([22866, 8]),\n",
       " torch.Size([22866]))"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# building X and Y dataset: train, validation, and test splits\n",
    "\n",
    "def get_X_and_Y(names, print_examples=False):\n",
    "    X, Y = [], []\n",
    "    for n in names:\n",
    "        block = [0] * NUM_OF_PREV_CHAR_TO_USE\n",
    "        for ch in n + '.':\n",
    "            ix = stoi[ch]\n",
    "            X.append(block)\n",
    "            Y.append(ix)\n",
    "            block = [*block[1:], ix]\n",
    "\n",
    "    X = torch.tensor(X)\n",
    "    Y = torch.tensor(Y)\n",
    "\n",
    "    return X, Y\n",
    "\n",
    "\n",
    "random.shuffle(names)\n",
    "n1 = int(len(names) * TRAIN_VALIDATION_TEST_SPLIT[0])\n",
    "n2 = int(len(names) *\n",
    "         (TRAIN_VALIDATION_TEST_SPLIT[0] + TRAIN_VALIDATION_TEST_SPLIT[1]))\n",
    "\n",
    "X_TRAIN, Y_TRAIN = get_X_and_Y(names[0:n1])\n",
    "X_VALID, Y_VALID = get_X_and_Y(names[n1:n2])\n",
    "X_TEST , Y_TEST = get_X_and_Y(names[n2:])\n",
    "\n",
    "X_TRAIN.shape, Y_TRAIN.shape, X_VALID.shape, X_VALID.shape, X_TEST.shape, Y_TEST.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "........ --> y\n",
      ".......y --> u\n",
      "......yu --> h\n",
      ".....yuh --> e\n",
      "....yuhe --> n\n",
      "...yuhen --> g\n"
     ]
    }
   ],
   "source": [
    "# a few examples of X and Y\n",
    "\n",
    "for x, y in zip(X_TRAIN[0:6], Y_TRAIN):\n",
    "    print(\n",
    "        ''.join([itos[_x.item()] for _x in x]),\n",
    "        '-->',\n",
    "        itos[y.item()]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0, 25]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_TRAIN[0:2]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 68, 27)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EMBEDDING_DIM, NUMBER_OF_NEURONS, VOCAB_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22397"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note: when doing batch norm, no bias in linear layer is needed.\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(VOCAB_SIZE, EMBEDDING_DIM),\n",
    "\n",
    "    # first biagram\n",
    "    Flatten(2),\n",
    "    Linear(EMBEDDING_DIM * 2, NUMBER_OF_NEURONS, bias=False),\n",
    "    BatchNorm1D(dim_features=NUMBER_OF_NEURONS),\n",
    "    Tanh(),\n",
    "\n",
    "    # second biagram\n",
    "    Flatten(2),\n",
    "    Linear(NUMBER_OF_NEURONS * 2, NUMBER_OF_NEURONS, bias=False),\n",
    "    BatchNorm1D(dim_features=NUMBER_OF_NEURONS),\n",
    "    Tanh(),\n",
    "\n",
    "    # third biagram\n",
    "    Flatten(2),\n",
    "    Linear(NUMBER_OF_NEURONS * 2, NUMBER_OF_NEURONS, bias=False),\n",
    "    BatchNorm1D(dim_features=NUMBER_OF_NEURONS),\n",
    "    Tanh(),\n",
    "\n",
    "    Linear(NUMBER_OF_NEURONS, VOCAB_SIZE)\n",
    "])\n",
    "\n",
    "# parameters initialization:\n",
    "parameters = model.parameters()\n",
    "with torch.no_grad():\n",
    "    model.layers[-1].W *= 0.1  # less confident on the last layer\n",
    "\n",
    "# setting requires grad for parameters\n",
    "for p in parameters:\n",
    "    p.requires_grad = True\n",
    "\n",
    "sum([p.nelement() for p in parameters])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for       0/  20000 = 3.31422\n",
      "loss for    2000/  20000 = 1.88942\n",
      "loss for    4000/  20000 = 1.96987\n",
      "loss for    6000/  20000 = 2.11756\n",
      "loss for    8000/  20000 = 1.69920\n",
      "loss for   10000/  20000 = 2.20956\n",
      "loss for   12000/  20000 = 2.43694\n",
      "loss for   14000/  20000 = 2.29047\n",
      "loss for   16000/  20000 = 2.03670\n",
      "loss for   18000/  20000 = 1.93558\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.071419824361801"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_STEPS = 20000\n",
    "step = []\n",
    "list_loss = []\n",
    "\n",
    "for iter in range(MAX_STEPS):\n",
    "\n",
    "    # minibatch\n",
    "    batch_idx = torch.randint(0, len(X_TRAIN), (BATCH_SIZE,))\n",
    "    x_batch, y_batch = X_TRAIN[batch_idx], Y_TRAIN[batch_idx]\n",
    "\n",
    "    # forward pass    \n",
    "    logits = model(x_batch, train=True)\n",
    "\n",
    "    # loss function based on logits\n",
    "    loss = torch.nn.functional.cross_entropy(logits, y_batch)\n",
    "    list_loss.append(loss.item())\n",
    "    step.append(iter)\n",
    "\n",
    "    # backward pass:\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "\n",
    "    # update\n",
    "    lr = 0.1 if iter < int(0.7 * MAX_STEPS) else 0.01\n",
    "    for p in parameters:\n",
    "        p.data -= lr * p.grad\n",
    "\n",
    "    # log\n",
    "    if iter % int(MAX_STEPS / 10) == 0:\n",
    "        print(f\"loss for {iter:7d}/{MAX_STEPS:7d} = {loss.item():.5f}\")\n",
    "\n",
    "sum(list_loss[-100:]) / 100  # last loss achieved in training set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding       shape =  torch.Size([32, 8, 10])\n",
      "Flatten         shape =  torch.Size([32, 4, 20])\n",
      "Linear          shape =  torch.Size([32, 4, 68])\n",
      "BatchNorm1D     shape =  torch.Size([32, 4, 68])\n",
      "Tanh            shape =  torch.Size([32, 4, 68])\n",
      "Flatten         shape =  torch.Size([32, 2, 136])\n",
      "Linear          shape =  torch.Size([32, 2, 68])\n",
      "BatchNorm1D     shape =  torch.Size([32, 2, 68])\n",
      "Tanh            shape =  torch.Size([32, 2, 68])\n",
      "Flatten         shape =  torch.Size([32, 136])\n",
      "Linear          shape =  torch.Size([32, 68])\n",
      "BatchNorm1D     shape =  torch.Size([32, 68])\n",
      "Tanh            shape =  torch.Size([32, 68])\n",
      "Linear          shape =  torch.Size([32, 27])\n"
     ]
    }
   ],
   "source": [
    "for l in model.layers:\n",
    "    print(f\"{l.__class__.__name__:15} shape =  {l.out.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# loss plot (smoothed)\n",
    "\n",
    "y = torch.tensor(list_loss).view(-1, 1000).mean(1).tolist()\n",
    "\n",
    "sns.lineplot(x=range(len(y)), y=y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train=2.05883526802063 \n",
      " valid=2.09456729888916 \n",
      " test=2.0942931175231934\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def eval(x_eval, y_eval):\n",
    "    logits = model(x_eval, train=False)\n",
    "    loss = torch.nn.functional.cross_entropy(logits, y_eval)\n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "print(f\"train={eval(X_TRAIN, Y_TRAIN)} \\n valid={eval(X_VALID, Y_VALID)} \\n test={eval(X_TEST, Y_TEST)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12099657768651609"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([p.nelement() for p in parameters]) / X_TRAIN.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/81/p29glqk579jc_zzy2qdvx0g80000gn/T/ipykernel_36057/666770995.py:11: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = torch.nn.functional.softmax(logits)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['junide',\n",
       " 'janasia',\n",
       " 'prefay',\n",
       " 'adiya',\n",
       " 'jirrito',\n",
       " 'cossaree',\n",
       " 'kalinaa',\n",
       " 'zamileaha',\n",
       " 'khedainr',\n",
       " 'amells']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generating New Names\n",
    "\n",
    "def get_new_names_with_nn(n):\n",
    "    names = []\n",
    "    for _ in range(n):\n",
    "        out = []\n",
    "        block = [0] * NUM_OF_PREV_CHAR_TO_USE\n",
    "        while True:\n",
    "            temp_x = torch.tensor([block])\n",
    "            logits = model(temp_x, train=False)\n",
    "            probs = torch.nn.functional.softmax(logits)\n",
    "            ix = torch.multinomial(probs, num_samples=1, replacement=True, generator=g).item()\n",
    "            block = [*block[1:], ix]\n",
    "            out.append(ix)\n",
    "            if ix == 0:\n",
    "                break\n",
    "        names.append(''.join(itos[i] for i in out[:-1]))\n",
    "    return names\n",
    "\n",
    "get_new_names_with_nn(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graveyard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([182625, 8])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_TRAIN.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 8]) torch.Size([4, 27])\n",
      "tensor([[ 0,  0,  0, 19,  5, 14,  1,  9],\n",
      "        [ 0,  0,  0,  0,  0,  2,  5,  3],\n",
      "        [ 0,  0,  0,  0,  0,  0,  0, 14],\n",
      "        [21,  2, 18,  5,  5, 12, 25, 14]])\n"
     ]
    }
   ],
   "source": [
    "# example\n",
    "ix = torch.randint(low=0, high=X_TRAIN.shape[0], size=(4,))\n",
    "xb, yb = X_TRAIN[ix], Y_TRAIN[ix]\n",
    "logits = model(xb, train=False)\n",
    "print(xb.shape, logits.shape)\n",
    "print(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 4,  1, 17,  9,  4,  4,  4,  1,  3,  9],\n",
       "         [17,  7,  1, 15,  6, 19,  0, 17, 17,  2],\n",
       "         [ 0,  3,  5,  2,  0, 16, 18,  3, 10,  2],\n",
       "         [ 8,  7, 15,  0, 16, 13,  5,  4, 17,  7],\n",
       "         [10, 11,  7, 17, 13,  5,  1, 18, 18, 17],\n",
       "         [ 2, 13,  0,  7,  7, 19,  8, 10,  5, 10],\n",
       "         [13, 15, 10,  5,  1, 15, 13, 10,  3, 16],\n",
       "         [ 6, 17, 16,  7,  0,  6, 13, 14, 15, 17]],\n",
       "\n",
       "        [[15,  3, 11, 10,  7, 11, 15, 11, 15,  6],\n",
       "         [ 8, 16,  8, 16,  4,  9, 12,  6, 19,  4],\n",
       "         [18, 11,  2, 19, 10,  8, 10,  8, 10,  1],\n",
       "         [13, 19,  4,  4, 16, 13,  3,  5, 16,  3],\n",
       "         [14,  9, 12,  8,  8, 14, 13,  3, 11, 13],\n",
       "         [15, 17, 18, 19,  1, 17, 13, 15,  3, 11],\n",
       "         [ 6, 11, 18,  7, 10, 12, 10,  6,  6,  4],\n",
       "         [18,  2,  9, 11, 19, 19, 16,  7,  0,  5]]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = torch.randint(0, 20, (2, 8, 10))\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 4,  1, 17,  9,  4,  4,  4,  1,  3,  9, 17,  7,  1, 15,  6, 19,  0,\n",
       "          17, 17,  2],\n",
       "         [ 0,  3,  5,  2,  0, 16, 18,  3, 10,  2,  8,  7, 15,  0, 16, 13,  5,\n",
       "           4, 17,  7],\n",
       "         [10, 11,  7, 17, 13,  5,  1, 18, 18, 17,  2, 13,  0,  7,  7, 19,  8,\n",
       "          10,  5, 10],\n",
       "         [13, 15, 10,  5,  1, 15, 13, 10,  3, 16,  6, 17, 16,  7,  0,  6, 13,\n",
       "          14, 15, 17]],\n",
       "\n",
       "        [[15,  3, 11, 10,  7, 11, 15, 11, 15,  6,  8, 16,  8, 16,  4,  9, 12,\n",
       "           6, 19,  4],\n",
       "         [18, 11,  2, 19, 10,  8, 10,  8, 10,  1, 13, 19,  4,  4, 16, 13,  3,\n",
       "           5, 16,  3],\n",
       "         [14,  9, 12,  8,  8, 14, 13,  3, 11, 13, 15, 17, 18, 19,  1, 17, 13,\n",
       "          15,  3, 11],\n",
       "         [ 6, 11, 18,  7, 10, 12, 10,  6,  6,  4, 18,  2,  9, 11, 19, 19, 16,\n",
       "           7,  0,  5]]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([test[:, ::2, :], test[:, 1::2, :]], dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 10])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# embedding\n",
    "model.layers[0].out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 80])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# flatten\n",
    "model.layers[1].out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 200])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# linear\n",
    "model.layers[2].out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 200])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batchnorm\n",
    "model.layers[3].out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 200])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tanh\n",
    "model.layers[4].out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 27])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# second linear\n",
    "model.layers[5].out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
